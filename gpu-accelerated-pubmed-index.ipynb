{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA Gave Me a \\$15K Data Science Workstation - here's what I did with it\n",
    "\n",
    "This notebook is an adaptation of my Towards Data Science Article availabe [here](https://towardsdatascience.com/nvidia-gave-me-a-15k-data-science-workstation-heres-what-i-did-with-it-70cfb069fc35)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download and Process XML Data\n",
    "This step gives you example data to work with for the tutorial. For the actual post, I worked with all of Pubmed. However, for the sake of brevity here I use the abstracts from a single file.\n",
    "\n",
    "Here, I walked through the example with one Pubmed file, although you could repeat this process for every file in the directory. I explicitely chose a document that has newer abstracts. Make sure your computer has enough processing power to handle this part of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-02 15:49:13--  https://mbr.nlm.nih.gov/Download/Baselines/2019/pubmed19n0972.xml.gz\n",
      "Resolving mbr.nlm.nih.gov (mbr.nlm.nih.gov)... 130.14.53.15, 2607:f220:41e:7053::15\n",
      "Connecting to mbr.nlm.nih.gov (mbr.nlm.nih.gov)|130.14.53.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8755134 (8.3M) [application/x-gzip]\n",
      "Saving to: ‘pubmed19n0972.xml.gz’\n",
      "\n",
      "pubmed19n0972.xml.g 100%[===================>]   8.35M   294KB/s    in 25s     \n",
      "\n",
      "2020-03-02 15:49:39 (338 KB/s) - ‘pubmed19n0972.xml.gz’ saved [8755134/8755134]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download single Pubmed XML from the directory\n",
    "!wget https://mbr.nlm.nih.gov/Download/Baselines/2019/pubmed19n0972.xml.gz\n",
    "# unzip it\n",
    "!gunzip pubmed19n0972.xml.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to parse the XML to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_file_text(path):\n",
    "    \n",
    "    with open(path, \"r\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    return text\n",
    "\n",
    "def get_pubmed_articles_from_xml_text(text, field=\"PubmedArticle\"):\n",
    "\n",
    "    soup = BeautifulSoup(text,\"xml\")\n",
    "    documents = soup.find_all(field)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def get_pubmed_article_fields(soup, fields=[\"AbstractText\",\"Year\"]):\n",
    "    d = {}\n",
    "    \n",
    "    for f in fields:\n",
    "        item = soup.find(f).text\n",
    "        d[f] = '' if item is None else item\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PubmedArticle>\n",
      "<MedlineCitation Owner=\"NLM\" Status=\"Publisher\">\n",
      "<PMID Version=\"1\">30516271</PMID>\n",
      "<DateRevised>\n",
      "<Year>2018</Year>\n",
      "<Month>12</Month>\n",
      "<Day>05</Day>\n",
      "</DateRevised>\n",
      "<Article PubModel=\"Print-Electronic\">\n",
      "<Journal>\n",
      "<ISSN IssnType=\"Print\">0012-9658</ISSN>\n",
      "<JournalIssue CitedMedium=\"Print\">\n",
      "<PubDate>\n",
      "<Year>2018</Year>\n",
      "<Month>Dec</Month>\n",
      "<Day>05</Day>\n",
      "</PubDate>\n",
      "</JournalIssue>\n",
      "<Title>Ecology</Title>\n",
      "<ISOAbbreviation>Ecology</ISOAbbreviation>\n",
      "</Journal>\n",
      "<ArticleTitle>Spatial scale modulates the inference of metacommunity assembly processes.</ArticleTitle>\n",
      "<ELocationID EIdType=\"doi\" ValidYN=\"Y\">10.1002/ecy.2576</ELocationID>\n",
      "<Abstract>\n",
      "<AbstractText>The abundance and distribution of species across the landscape depend on the interaction between local, spatial and stochastic processes. However, empirical syntheses relating these processes to spatio-temporal patterns of structure in metacommunities remains elusive. One important reason for this lack of synthesis is that the relative importance of the core assembly processes (dispersal, selection and drift) critically depends on the spatial grain and extent over which communities are studied. To illustrate this, we simulated different aspects of community assembly on heterogeneous landscapes, including the strength of response to environmental heterogeneity (inherent to niche theory) versus dispersal and stochastic drift (inherent to neutral theory). We show that increasing spatial extent leads to increasing importance of niche selection, whereas increasing spatial grain leads to decreasing importance of niche selection. The strength of these scaling effects depended on environment configuration, dispersal capacity and niche breadth. By mapping the variation observed from the scaling effects in simulations, we could recreate the entire range of variation observed within and among empirical studies. This means that variation in the relative importance of assembly processes among empirical studies is largely scale dependent and cannot be directly compared. The scaling coefficient of the relative contribution of assembly processes, however, can be interpreted as a scale-integrative estimate to compare assembly processes across different regions and ecosystems. This emphasizes the necessity to consider spatial scaling as an explicit component of studies intended to infer the importance of community assembly processes. This article is protected by copyright. All rights reserved.</AbstractText>\n",
      "<CopyrightInformation>This article is protected by copyright. All rights reserved.</CopyrightInformation>\n",
      "</Abstract>\n",
      "<AuthorList CompleteYN=\"Y\">\n",
      "<Author ValidYN=\"Y\">\n",
      "<LastName>Viana</LastName>\n",
      "<ForeName>Duarte S</ForeName>\n",
      "<Initials>DS</Initials>\n",
      "<AffiliationInfo>\n",
      "<Affiliation>German Centre for Integrative Biodiversity Research (iDiv) Halle-Jena-Leipzig, Germany.</Affiliation>\n",
      "</AffiliationInfo>\n",
      "</Author>\n",
      "<Author ValidYN=\"Y\">\n",
      "<LastName>Chase</LastName>\n",
      "<ForeName>Jonathan M</ForeName>\n",
      "<Initials>JM</Initials>\n",
      "<AffiliationInfo>\n",
      "<Affiliation>German Centre for Integrative Biodiversity Research (iDiv) Halle-Jena-Leipzig, Germany.</Affiliation>\n",
      "</AffiliationInfo>\n",
      "<AffiliationInfo>\n",
      "<Affiliation>Institute for Computer Science, Martin Luther University Halle-Wittenberg, Halle (Saale), Germany.</Affiliation>\n",
      "</AffiliationInfo>\n",
      "</Author>\n",
      "</AuthorList>\n",
      "<Language>eng</Language>\n",
      "<PublicationTypeList>\n",
      "<PublicationType UI=\"D016428\">Journal Article</PublicationType>\n",
      "</PublicationTypeList>\n",
      "<ArticleDate DateType=\"Electronic\">\n",
      "<Year>2018</Year>\n",
      "<Month>12</Month>\n",
      "<Day>05</Day>\n",
      "</ArticleDate>\n",
      "</Article>\n",
      "<MedlineJournalInfo>\n",
      "<Country>United States</Country>\n",
      "<MedlineTA>Ecology</MedlineTA>\n",
      "<NlmUniqueID>0043541</NlmUniqueID>\n",
      "<ISSNLinking>0012-9658</ISSNLinking>\n",
      "</MedlineJournalInfo>\n",
      "<KeywordList Owner=\"NOTNLM\">\n",
      "<Keyword MajorTopicYN=\"N\">Community assembly</Keyword>\n",
      "<Keyword MajorTopicYN=\"N\">Dispersal</Keyword>\n",
      "<Keyword MajorTopicYN=\"N\">Ecological drift</Keyword>\n",
      "<Keyword MajorTopicYN=\"N\">Metacommunity</Keyword>\n",
      "<Keyword MajorTopicYN=\"N\">Neutral theory</Keyword>\n",
      "<Keyword MajorTopicYN=\"N\">Niche selection</Keyword>\n",
      "<Keyword MajorTopicYN=\"N\">Sampling grain</Keyword>\n",
      "<Keyword MajorTopicYN=\"N\">Spatial extent</Keyword>\n",
      "<Keyword MajorTopicYN=\"N\">Spatial scale</Keyword>\n",
      "</KeywordList>\n",
      "</MedlineCitation>\n",
      "<PubmedData>\n",
      "<History>\n",
      "<PubMedPubDate PubStatus=\"entrez\">\n",
      "<Year>2018</Year>\n",
      "<Month>12</Month>\n",
      "<Day>6</Day>\n",
      "<Hour>6</Hour>\n",
      "<Minute>0</Minute>\n",
      "</PubMedPubDate>\n",
      "<PubMedPubDate PubStatus=\"pubmed\">\n",
      "<Year>2018</Year>\n",
      "<Month>12</Month>\n",
      "<Day>6</Day>\n",
      "<Hour>6</Hour>\n",
      "<Minute>0</Minute>\n",
      "</PubMedPubDate>\n",
      "<PubMedPubDate PubStatus=\"medline\">\n",
      "<Year>2018</Year>\n",
      "<Month>12</Month>\n",
      "<Day>6</Day>\n",
      "<Hour>6</Hour>\n",
      "<Minute>0</Minute>\n",
      "</PubMedPubDate>\n",
      "</History>\n",
      "<PublicationStatus>aheadofprint</PublicationStatus>\n",
      "<ArticleIdList>\n",
      "<ArticleId IdType=\"pubmed\">30516271</ArticleId>\n",
      "<ArticleId IdType=\"doi\">10.1002/ecy.2576</ArticleId>\n",
      "</ArticleIdList>\n",
      "</PubmedData>\n",
      "</PubmedArticle>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-117b58df1212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pubmed_article_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mlis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3657787a57a4>\u001b[0m in \u001b[0;36mget_pubmed_article_fields\u001b[0;34m(soup, fields)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "RAW_DATA = \"pubmed19n0972.xml\"\n",
    "\n",
    "text = get_file_text(RAW_DATA)\n",
    "documents = get_pubmed_articles_from_xml_text(text)\n",
    "print(documents[0])\n",
    "lis = []\n",
    "for doc in documents:\n",
    "    fields = get_pubmed_article_fields(doc)\n",
    "    lis.append(fields)\n",
    "    \n",
    "df = pd.DataFrame(lis)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a more intensive and particular way to process the documents that can lead to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = soup.find_all(\"Abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-49e602f2e461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "soup.find(\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path = ['', '/data/python/anaconda3/envs/rapids-env/lib/python37.zip', '/data/python/anaconda3/envs/rapids-env/lib/python3.7', '/data/python/anaconda3/envs/kyle-test/lib/python3.7/lib-dynload', '/home/gallak12/.local/lib/python3.7/site-packages', '/data/python/anaconda3/envs/kyle-test/lib/python3.7/site-packages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ~/.local/share/jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/data/python/anaconda3/bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
